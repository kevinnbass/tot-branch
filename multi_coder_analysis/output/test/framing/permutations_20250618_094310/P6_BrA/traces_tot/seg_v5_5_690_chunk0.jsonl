{"Q": 1, "answer": "no", "rationale": "The segment does not contain an intensifier or comparative adjective directly modifying a risk-adjective.", "method": "llm_batch", "batch_id": "batch_1_15456", "batch_size": 260, "batch_pos": 229}
{"Q": 2, "answer": "no", "rationale": "The segment provides factual description of cases/symptoms ('have been reported', 'developed pink eye', 'had mild respiratory symptoms') without high-potency framing.", "method": "llm_batch", "batch_id": "batch_2_15560", "batch_size": 260, "batch_pos": 203}
{"Q": 3, "answer": "no", "rationale": "The segment uses plain verbs ('linked', 'have been reported', 'developed', 'had'). 'Three previous cases', 'Two of those workers', 'one' are quantities, but verbs are plain.", "method": "llm_batch", "batch_id": "batch_3_15928", "batch_size": 260, "batch_pos": 169}
{"Q": 4, "answer": "no", "rationale": "The segment contains no question.", "method": "llm_batch", "batch_id": "batch_4_16832", "batch_size": 260, "batch_pos": 163}
{"Q": 5, "answer": "no", "rationale": "The segment reports previous human cases and symptoms, lacking explicit calming language.", "method": "llm_batch", "batch_id": "batch_5_1172", "batch_size": 260, "batch_pos": 161}
{"Q": 6, "answer": "no", "rationale": "The segment mentions 'Three previous cases', 'Two of those workers', and 'one had mild respiratory symptoms' but not minimiser + scale contrast.", "method": "llm_batch", "batch_id": "batch_6_17448", "batch_size": 260, "batch_pos": 143}
{"Q": 7, "answer": "no", "rationale": "The segment does not contain a bare negation.", "method": "llm_batch", "batch_id": "batch_7_13600", "batch_size": 260, "batch_pos": 140}
{"Q": 8, "answer": "no", "rationale": "The segment reports past cases and symptoms, not capabilities or preparedness.", "method": "llm_batch", "batch_id": "batch_8_7588", "batch_size": 260, "batch_pos": 51}
{"Q": 9, "answer": "yes", "rationale": "Reports metrics ('Three previous cases', 'Two... developed pink eye', 'one had mild respiratory symptoms') using standard reporting.", "method": "llm_batch", "batch_id": "batch_9_8464", "batch_size": 260, "batch_pos": 61}
