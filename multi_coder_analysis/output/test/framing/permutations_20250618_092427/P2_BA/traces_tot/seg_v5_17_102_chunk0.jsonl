{"Q": 1, "answer": "no", "rationale": "The segment describes an update to factual numbers, containing no intensifiers or comparative risk-adjectives.", "method": "llm_batch", "batch_id": "batch_1_7520", "batch_size": 20, "batch_pos": 6}
{"Q": 2, "answer": "no", "rationale": "The segment describes an update to numbers using neutral verbs like 'updated' and 'correct', not high-potency language.", "method": "llm_batch", "batch_id": "batch_2_15000", "batch_size": 19, "batch_pos": 6}
{"Q": 3, "answer": "no", "rationale": "The verb 'killed' is a containment verb, which neutralizes the pattern even with large numbers, as per the Q3 rules.", "method": "llm_batch", "batch_id": "batch_3_7696", "batch_size": 18, "batch_pos": 6}
{"Q": 4, "answer": "no", "rationale": "This is an editorial note about corrections and does not contain any question.", "method": "llm_batch", "batch_id": "batch_4_14296", "batch_size": 18, "batch_pos": 6}
{"Q": 5, "answer": "no", "rationale": "This is an editorial note about a correction and contains no explicit calming cues.", "method": "llm_batch", "batch_id": "batch_5_16888", "batch_size": 18, "batch_pos": 6}
{"Q": 6, "answer": "no", "rationale": "The segment is a factual correction of numbers and does not use a minimiser with scale contrast for reassurance.", "method": "llm_batch", "batch_id": "batch_6_17568", "batch_size": 17, "batch_pos": 5}
{"Q": 7, "answer": "no", "rationale": "The segment does not contain any bare negation or explicit calming cue.", "method": "llm_batch", "batch_id": "batch_7_12396", "batch_size": 17, "batch_pos": 5}
{"Q": 8, "answer": "no", "rationale": "The segment is a meta-statement about a story update/correction, not capabilities, preparedness, or safeguards.", "method": "llm_batch", "batch_id": "batch_8_17400", "batch_size": 16, "batch_pos": 4}
{"Q": 9, "answer": "yes", "rationale": "The segment reports numerical metrics ('22 million', '13 million instead of 18 million') using standard descriptive verbs ('correct the total number') without vivid language or framing.", "method": "llm_batch", "batch_id": "batch_9_17156", "batch_size": 13, "batch_pos": 3}
