{"Q": 1, "answer": "no", "rationale": "The segment contains 'fatal' but it is not modified by an intensifier or comparative adjective.", "method": "llm_batch", "batch_id": "batch_1_15512", "batch_size": 260, "batch_pos": 119}
{"Q": 2, "answer": "no", "rationale": "'Fatal cases' is a factual description of outcome, not high-potency framing.", "method": "llm_batch", "batch_id": "batch_2_15612", "batch_size": 260, "batch_pos": 114}
{"Q": 3, "answer": "no", "rationale": "The segment uses 'have been' (plain outcome verb) paired with 'fatal cases' (impact).", "method": "llm_batch", "batch_id": "batch_3_17132", "batch_size": 260, "batch_pos": 91}
{"Q": 4, "answer": "no", "rationale": "Segment does not contain a question.", "method": "llm_batch", "batch_id": "batch_4_17148", "batch_size": 260, "batch_pos": 80}
{"Q": 5, "answer": "no", "rationale": "The segment reports fatal cases, which is not a calming cue.", "method": "llm_batch", "batch_id": "batch_5_2912", "batch_size": 260, "batch_pos": 80}
{"Q": 6, "answer": "no", "rationale": "No minimiser + scale contrast found.", "method": "llm_batch", "batch_id": "batch_6_14396", "batch_size": 260, "batch_pos": 75}
{"Q": 7, "answer": "no", "rationale": "The segment does not contain a bare negation.", "method": "llm_batch", "batch_id": "batch_7_13140", "batch_size": 260, "batch_pos": 68}
{"Q": 8, "answer": "no", "rationale": "The segment states a fact about past events, not capabilities or preparedness.", "method": "llm_batch", "batch_id": "batch_8_1800", "batch_size": 260, "batch_pos": 51}
{"Q": 9, "answer": "no", "rationale": "The segment reports fatal cases, not prices or economic metrics.", "method": "llm_batch", "batch_id": "batch_9_16864", "batch_size": 260, "batch_pos": 160}
{"Q": 10, "answer": "no", "rationale": "The segment reports past events, not speculation about future relief.", "method": "llm_batch", "batch_id": "batch_10_16828", "batch_size": 260, "batch_pos": 152}
{"Q": 11, "answer": "no", "rationale": "Quote is a factual statement, not framing the threat.", "method": "llm_batch", "batch_id": "batch_11_15740", "batch_size": 260, "batch_pos": 142}
