{"Q": 1, "answer": "no", "rationale": "The segment does not contain an intensifier or comparative adjective directly modifying a risk-adjective.", "method": "llm_batch", "batch_id": "batch_1_4640", "batch_size": 217, "batch_pos": 177}
{"Q": 2, "answer": "no", "rationale": "Factual statement about symptoms. 'sick' is not high-potency.", "method": "llm_batch", "batch_id": "batch_2_14348", "batch_size": 158, "batch_pos": 123}
{"Q": 3, "answer": "no", "rationale": "Contains a quote about trust, not impact with a moderate verb + scale.", "method": "llm_batch", "batch_id": "batch_3_11712", "batch_size": 67, "batch_pos": 35}
{"Q": 4, "answer": "no", "rationale": "No loaded rhetorical question is present in the text.", "method": "llm_batch", "batch_id": "batch_4_16996", "batch_size": 53, "batch_pos": 22}
{"Q": 5, "answer": "no", "rationale": "Reports a specific mild symptom factually.", "method": "llm_batch", "batch_id": "batch_5_17168", "batch_size": 50, "batch_pos": 19}
{"Q": 6, "answer": "no", "rationale": "No minimiser or scale contrast found.", "method": "llm_batch", "batch_id": "batch_6_3220", "batch_size": 249, "batch_pos": 218}
{"Q": 7, "answer": "no", "rationale": "The segment states most people have pink eye, not a negation.", "method": "llm_batch", "batch_id": "batch_7_3232", "batch_size": 236, "batch_pos": 205}
{"Q": 8, "answer": "no", "rationale": "Factual report of symptoms, not capability or preparedness.", "method": "llm_batch", "batch_id": "batch_8_17100", "batch_size": 260, "batch_pos": 253}
{"Q": 9, "answer": "no", "rationale": "The segment reports symptoms, not numerical metrics.", "method": "llm_batch", "batch_id": "batch_9_15784", "batch_size": 225, "batch_pos": 204}
{"Q": 10, "answer": "no", "rationale": "The segment states a current fact about symptoms, not speculation about future relief or improvement.", "method": "llm_batch", "batch_id": "batch_10_16048", "batch_size": 28, "batch_pos": 10}
{"Q": 11, "answer": "no", "rationale": "Segment contains no direct quote or clearly attributed statement.", "method": "llm_batch", "batch_id": "batch_11_14256", "batch_size": 240, "batch_pos": 224}
