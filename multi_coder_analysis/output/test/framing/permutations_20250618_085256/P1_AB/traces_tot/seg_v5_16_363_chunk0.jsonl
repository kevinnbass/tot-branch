{"Q": 1, "answer": "no", "rationale": "'susceptible' is not modified by an intensifier or comparative.", "method": "llm_batch", "batch_id": "batch_1_4640", "batch_size": 217, "batch_pos": 199}
{"Q": 2, "answer": "no", "rationale": "Factual statement about susceptibility. No high-potency language.", "method": "llm_batch", "batch_id": "batch_2_14348", "batch_size": 158, "batch_pos": 142}
{"Q": 3, "answer": "no", "rationale": "States susceptibility, not impact with a moderate verb + scale.", "method": "llm_batch", "batch_id": "batch_3_11712", "batch_size": 67, "batch_pos": 54}
{"Q": 4, "answer": "no", "rationale": "No loaded rhetorical question is present in the text.", "method": "llm_batch", "batch_id": "batch_4_16996", "batch_size": 53, "batch_pos": 41}
{"Q": 5, "answer": "no", "rationale": "Reports susceptibility based on past events factually.", "method": "llm_batch", "batch_id": "batch_5_17168", "batch_size": 50, "batch_pos": 38}
{"Q": 6, "answer": "no", "rationale": "No minimiser or scale contrast found.", "method": "llm_batch", "batch_id": "batch_6_3220", "batch_size": 249, "batch_pos": 237}
{"Q": 7, "answer": "no", "rationale": "The segment states previous outbreaks show susceptibility, not a negation.", "method": "llm_batch", "batch_id": "batch_7_3232", "batch_size": 236, "batch_pos": 224}
{"Q": 8, "answer": "no", "rationale": "The segment states a fact about susceptibility, not capability or preparedness.", "method": "llm_batch", "batch_id": "batch_8_8244", "batch_size": 19, "batch_pos": 9}
{"Q": 9, "answer": "no", "rationale": "The segment reports susceptibility, not numerical metrics.", "method": "llm_batch", "batch_id": "batch_9_15784", "batch_size": 225, "batch_pos": 217}
{"Q": 10, "answer": "no", "rationale": "The segment states historical events and current susceptibility, not speculation about future relief.", "method": "llm_batch", "batch_id": "batch_10_16048", "batch_size": 28, "batch_pos": 21}
{"Q": 11, "answer": "no", "rationale": "Segment contains no direct quote or clearly attributed statement.", "method": "llm_batch", "batch_id": "batch_11_14256", "batch_size": 240, "batch_pos": 234}
