{"Q": 1, "answer": "no", "rationale": "'Most of the seals' uses a superlative but modifies 'seals' (noun), not a risk-adjective.", "method": "llm_batch", "batch_id": "batch_1_14764", "batch_size": 260, "batch_pos": 116}
{"Q": 2, "answer": "no", "rationale": "The segment reports factual information using neutral language.", "method": "llm_batch", "batch_id": "batch_2_7520", "batch_size": 260, "batch_pos": 115}
{"Q": 3, "answer": "no", "rationale": "'found dead' is a plain outcome.", "method": "llm_batch", "batch_id": "batch_3_16732", "batch_size": 260, "batch_pos": 105}
{"Q": 4, "answer": "no", "rationale": "The segment does not contain a loaded rhetorical question.", "method": "llm_batch", "batch_id": "batch_4_16524", "batch_size": 260, "batch_pos": 101}
{"Q": 5, "answer": "no", "rationale": "Reports deaths; lacks explicit calming language.", "method": "llm_batch", "batch_id": "batch_5_16952", "batch_size": 260, "batch_pos": 101}
{"Q": 6, "answer": "no", "rationale": "The segment does not contain a minimiser used in conjunction with a scale contrast.", "method": "llm_batch", "batch_id": "batch_6_14436", "batch_size": 260, "batch_pos": 95}
{"Q": 7, "answer": "no", "rationale": "The segment states a fact, not a bare negation.", "method": "llm_batch", "batch_id": "batch_7_6516", "batch_size": 260, "batch_pos": 94}
{"Q": 8, "answer": "no", "rationale": "Reports a fact about the seals, not capability/preparedness/safeguard.", "method": "llm_batch", "batch_id": "batch_8_17224", "batch_size": 260, "batch_pos": 83}
{"Q": 9, "answer": "no", "rationale": "The segment reports the condition of seals, not prices or numerical metrics.", "method": "llm_batch", "batch_id": "batch_9_16428", "batch_size": 260, "batch_pos": 40}
{"Q": 10, "answer": "no", "rationale": "The segment reports on the state of found seals, not speculating about future relief.", "method": "llm_batch", "batch_id": "batch_10_16444", "batch_size": 260, "batch_pos": 24}
{"Q": 11, "answer": "no", "rationale": "No direct quote or attributed statement providing a frame.", "method": "llm_batch", "batch_id": "batch_11_4464", "batch_size": 260, "batch_pos": 24}
