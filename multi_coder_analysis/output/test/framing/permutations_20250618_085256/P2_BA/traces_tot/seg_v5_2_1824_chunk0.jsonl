{"Q": 1, "answer": "no", "rationale": "The segment does not contain an intensifier or comparative adjective directly modifying a risk-adjective.", "method": "llm_batch", "batch_id": "batch_1_15604", "batch_size": 260, "batch_pos": 19}
{"Q": 2, "answer": "no", "rationale": "The segment reports a human case factually, without high-potency verbs or metaphors.", "method": "llm_batch", "batch_id": "batch_2_15308", "batch_size": 260, "batch_pos": 6}
{"Q": 3, "answer": "no", "rationale": "'detected' is a plain outcome verb, not a moderate verb paired with scale/impact.", "method": "llm_batch", "batch_id": "batch_3_17156", "batch_size": 260, "batch_pos": 249}
{"Q": 4, "answer": "no", "rationale": "The segment does not contain a loaded rhetorical question.", "method": "llm_batch", "batch_id": "batch_4_17392", "batch_size": 260, "batch_pos": 248}
{"Q": 5, "answer": "no", "rationale": "The segment reports the first human case without known animal contact, which is factual, not an explicit calming cue.", "method": "llm_batch", "batch_id": "batch_5_16336", "batch_size": 260, "batch_pos": 247}
{"Q": 6, "answer": "no", "rationale": "The segment does not contain a minimiser used in conjunction with a scale contrast.", "method": "llm_batch", "batch_id": "batch_6_3044", "batch_size": 260, "batch_pos": 242}
{"Q": 7, "answer": "no", "rationale": "No bare negation present.", "method": "llm_batch", "batch_id": "batch_7_16612", "batch_size": 260, "batch_pos": 242}
{"Q": 8, "answer": "no", "rationale": "Reports factual information about a human case, not capability/preparedness.", "method": "llm_batch", "batch_id": "batch_8_3644", "batch_size": 260, "batch_pos": 222}
{"Q": 9, "answer": "no", "rationale": "The segment reports the first human case detected, not primarily reporting numerical metrics.", "method": "llm_batch", "batch_id": "batch_9_14536", "batch_size": 260, "batch_pos": 134}
{"Q": 10, "answer": "no", "rationale": "The segment reports a human case but does not speculate about potential future relief or improvement.", "method": "llm_batch", "batch_id": "batch_10_15952", "batch_size": 260, "batch_pos": 108}
