{"Q": 1, "answer": "no", "rationale": "The segment does not contain an intensifier or comparative adjective modifying a risk-adjective.", "method": "llm_batch", "batch_id": "batch_1_16012", "batch_size": 260, "batch_pos": 4}
{"Q": 2, "answer": "no", "rationale": "The language states an identification factually.", "method": "llm_batch", "batch_id": "batch_2_16084", "batch_size": 260, "batch_pos": 222}
{"Q": 3, "answer": "no", "rationale": "The segment provides a factual statement about a person's role.", "method": "llm_batch", "batch_id": "batch_3_17192", "batch_size": 260, "batch_pos": 180}
{"Q": 4, "answer": "no", "rationale": "The segment does not contain a loaded rhetorical question.", "method": "llm_batch", "batch_id": "batch_4_12000", "batch_size": 260, "batch_pos": 169}
{"Q": 5, "answer": "no", "rationale": "The segment identifies a source without explicit calming language.", "method": "llm_batch", "batch_id": "batch_5_16720", "batch_size": 260, "batch_pos": 168}
{"Q": 6, "answer": "no", "rationale": "No 'minimiser + scale contrast' found.", "method": "llm_batch", "batch_id": "batch_6_10384", "batch_size": 260, "batch_pos": 142}
{"Q": 7, "answer": "no", "rationale": "The segment does not contain a bare negation.", "method": "llm_batch", "batch_id": "batch_7_16388", "batch_size": 260, "batch_pos": 135}
{"Q": 8, "answer": "no", "rationale": "Factual statement about a person's role, not capability or preparedness.", "method": "llm_batch", "batch_id": "batch_8_14680", "batch_size": 260, "batch_pos": 2}
{"Q": 9, "answer": "no", "rationale": "The segment states someone's title, not prices, economic data, or numerical metrics.", "method": "llm_batch", "batch_id": "batch_9_3168", "batch_size": 260, "batch_pos": 193}
{"Q": 10, "answer": "no", "rationale": "The segment states a title, not speculation about future relief.", "method": "llm_batch", "batch_id": "batch_10_4360", "batch_size": 260, "batch_pos": 53}
{"Q": 11, "answer": "no", "rationale": "No direct quote or attributed statement providing a dominant frame.", "method": "llm_batch", "batch_id": "batch_11_17824", "batch_size": 260, "batch_pos": 25}
