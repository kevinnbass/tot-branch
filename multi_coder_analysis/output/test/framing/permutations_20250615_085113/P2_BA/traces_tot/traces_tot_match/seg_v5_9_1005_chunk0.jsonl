{"Q": 1, "answer": "no", "rationale": "The segment does not contain an intensifier or comparative adjective directly modifying a risk-adjective.", "method": "llm_batch", "batch_id": "batch_1_13036", "batch_size": 259, "batch_pos": 222}
{"Q": 2, "answer": "no", "rationale": "The segment uses moderate language without high-potency verbs or metaphors.", "method": "llm_batch", "batch_id": "batch_2_15416", "batch_size": 245, "batch_pos": 209}
{"Q": 3, "answer": "no", "rationale": "The segment uses 'kill' which is a plain outcome verb (Rule 4), Neutral even with scale unless other cues fire.", "method": "llm_batch", "batch_id": "batch_3_16756", "batch_size": 238, "batch_pos": 205}
{"hop_idx": 4, "answer": "uncertain", "rationale": "Missing response from batch", "method": "fallback", "batch_id": "batch_4_1748", "batch_size": 237, "batch_pos": 204}
{"Q": 4, "answer": "no", "rationale": "No loaded rhetorical question is present in the text.", "method": "llm_batch_retry", "retry": 1, "batch_id": "batch_4_1748_r1", "batch_size": 237, "batch_pos": 204}
{"Q": 5, "answer": "no", "rationale": "This reports historical facts, lacking explicit calming language.", "method": "llm_batch", "batch_id": "batch_5_5288", "batch_size": 235, "batch_pos": 202}
{"Q": 6, "answer": "no", "rationale": "The segment uses 'smaller outbreaks' which is not a minimiser + scale contrast pattern.", "method": "llm_batch", "batch_id": "batch_6_15752", "batch_size": 225, "batch_pos": 193}
{"Q": 7, "answer": "no", "rationale": "The segment does not contain a bare negation.", "method": "llm_batch", "batch_id": "batch_7_10064", "batch_size": 224, "batch_pos": 192}
{"Q": 8, "answer": "no", "rationale": "The segment describes past outbreak impact, not current capabilities or preparedness.", "method": "llm_batch", "batch_id": "batch_8_15716", "batch_size": 184, "batch_pos": 152}
{"Q": 9, "answer": "yes", "rationale": "The segment reports numerical metrics ('kill 33 million', '9 million birds', 'smaller outbreaks') factually.", "method": "llm_batch", "batch_id": "batch_9_16816", "batch_size": 102, "batch_pos": 89}
