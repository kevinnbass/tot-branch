{"Q": 1, "answer": "no", "rationale": "The segment contains a psychological noun phrase ('real worry') and a statistic ('mortality rate has been 25 percent'), neither of which are Q1 cues.", "method": "llm_batch", "batch_id": "batch_1_18860", "batch_size": 217, "batch_pos": 125}
{"Q": 2, "answer": "no", "rationale": "'real worry' is a psychological state. 'mortality rate has been 25 percent' is a factual statement of severity/scale.", "method": "llm_batch", "batch_id": "batch_2_16160", "batch_size": 165, "batch_pos": 74}
{"Q": 4, "answer": "no", "rationale": "No loaded rhetorical question is present.", "method": "llm_batch", "batch_id": "batch_4_21296", "batch_size": 260, "batch_pos": 249}
{"Q": 5, "answer": "no", "rationale": "The segment reports a 'real worry' and high mortality rate, which are not calming cues.", "method": "llm_batch", "batch_id": "batch_5_19744", "batch_size": 260, "batch_pos": 244}
{"Q": 6, "answer": "no", "rationale": "The segment does not contain a minimiser used in conjunction with a scale contrast for reassurance.", "method": "llm_batch", "batch_id": "batch_6_6716", "batch_size": 260, "batch_pos": 209}
{"Q": 7, "answer": "no", "rationale": "No bare negation found.", "method": "llm_batch", "batch_id": "batch_7_21256", "batch_size": 260, "batch_pos": 197}
{"Q": 8, "answer": "no", "rationale": "Describes a worry and historical outcome, not a capability or preparedness measure.", "method": "llm_batch", "batch_id": "batch_8_13160", "batch_size": 253, "batch_pos": 198}
{"Q": 9, "answer": "no", "rationale": "Includes a concern ('real worry') alongside a numerical metric.", "method": "llm_batch", "batch_id": "batch_9_20644", "batch_size": 207, "batch_pos": 182}
{"Q": 10, "answer": "no", "rationale": "The segment does not speculate about potential future relief or improvement.", "method": "llm_batch", "batch_id": "batch_10_18656", "batch_size": 260, "batch_pos": 252}
{"Q": 11, "answer": "yes", "rationale": "Quote states 'The real worry is that...' and reports high mortality rate.||FRAME=Alarmist", "method": "llm_batch", "batch_id": "batch_11_3128", "batch_size": 224, "batch_pos": 207}
